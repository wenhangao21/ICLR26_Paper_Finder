{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TL;DR:** A tutorial on creating a simple paper recommender system using embeddings from paper abstracts.\n",
        "\n",
        "Recently, I shared a tool that helps people find relevant papers among 17,000+ ICLR 2026 submissions. To my surprise, the post attracted quite a bit of attention, much more than any of my posts about [my research](https://wenhangao21.github.io/tech_blogs/)üò¢.\n",
        "\n",
        "- [ICLR2026 Paper Finder on Hugging Face](https://huggingface.co/spaces/wenhanacademia/ICLR2026_PaperFinder)\n",
        "- [Open Source Repository](https://github.com/wenhangao21/ICLR26_Paper_Finder?tab=readme-ov-file)\n",
        "\n",
        "A few people reached out asking how the app was built. It‚Äôs actually very simple, so I thought I‚Äôd write a short blog/tutorial about it. **The algorithm took me less than 30 minutes to write (with the help from GPT-5-Instant)**, though the user interface ended up taking an entire afternoon (with the help from GPT-5-Instant). **You can run this notebook for free on Google Colab if you don‚Äôt have Jupyter Notebook installed.**"
      ],
      "metadata": {
        "id": "o6JH2VtvijAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Simple Paper Recommender with Language Embedding Models"
      ],
      "metadata": {
        "id": "WMD2PEkokpun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overall Pipeline"
      ],
      "metadata": {
        "id": "xwK_RAe02aeg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Data Retrieval:** Collect all paper submissions from OpenReview (For other venues, you can find API for or write a web scraper).\n",
        "2. **Data Processing:** Clean and structure the retrieved data into a usable format for downstream tasks.\n",
        "3. **Vector Database Construction:** Generate abstract embeddings with language embedding models and store them in a vector database to enable fast semantic similarity search (approximate k-NN).\n",
        "4. **Inference:** Query the database to identify the top-K most relevant submissions based on semantic similarity.\n",
        "\n",
        "Note:\n",
        "- **Data Retrieval and Processing:** We are given a collection of text documents (a collection of abstracts in our case):\n",
        "$$\n",
        "\\mathcal{T}=\\left\\{t_1, t_2, \\ldots, t_N\\right\\}.\\\\\n",
        "$$\n",
        "\n",
        "- **Vector Database Construction:** An embedding model maps a given text $t$ (an abstract in our case) into a high-dimensional continuous vector:\n",
        "  $$\n",
        "  \\operatorname{Embedding}_\\theta: t_i \\rightarrow e_i \\in \\mathbb{R}^d,\n",
        "  $$\n",
        "  where $\\operatorname{Embedding}_\\theta$ is the embedding model (you can think of the text embedding being the last feature before the the LM Head in a modern LLM), and $d$ is a fixed embedding dimension.\n",
        "\n",
        "  Now, we have a collection of embeddings $\\mathcal{E}=\\left\\{e_1, e_2, \\ldots, e_N\\right\\}$, and you can run approximate KNN algorithms (e.g. [FAISS](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)) on it for semantic search.\n"
      ],
      "metadata": {
        "id": "vOJE8wUn2cgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and Import Dependencies"
      ],
      "metadata": {
        "id": "VaphEiOZktDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install chromadb markdown google-generativeai sentence_transformers openreview-py"
      ],
      "metadata": {
        "collapsed": true,
        "id": "b3lSHp28lfKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openreview\n",
        "from openreview import tools\n",
        "import json\n",
        "import re\n",
        "import chromadb\n",
        "import google.generativeai as genai\n",
        "import chromadb.utils.embedding_functions as embedding_functions\n",
        "import textwrap\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "DA4ket59lL-8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Retrieval"
      ],
      "metadata": {
        "id": "_SfaAZvFk-8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the OpenReview API client\n",
        "client = openreview.api.OpenReviewClient(\n",
        "    baseurl=\"https://api2.openreview.net\",\n",
        "    username=\"<your openreview email>\",  # enter your openreview email and password here\n",
        "    password=\"<your openreview password>\"\n",
        ")\n",
        "# Extract all submissions to ICLR 2026\n",
        "notes = list(tools.iterget_notes(\n",
        "    client,\n",
        "    invitation=\"ICLR.cc/2026/Conference/-/Submission\"\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGZgZ0wxB5-9",
        "outputId": "5ad36135-a6b1-4d48-d8d6-3df56847185b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2596207524.py:8: DeprecationWarning: Call to deprecated function (or staticmethod) iterget_notes. (Use client.get_all_notes() instead) -- Deprecated since version 1.52.6.\n",
            "  notes = list(tools.iterget_notes(\n",
            "Getting Notes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 19713/19733 [00:09<00:00, 2019.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many submissions there are\n",
        "print(f\"Total submissions: {len(notes)}\")\n",
        "# Get all the possible atrributes\n",
        "key_counter = Counter(k for note in notes for k in note.content.keys())\n",
        "print(\"\\nAttribute occurrence counts:\")\n",
        "for key, count in key_counter.items():\n",
        "    print(f\"  {key}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss2AkqXMEBFu",
        "outputId": "726829cc-8de7-42ac-9504-d0530e06391f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total submissions: 19733\n",
            "\n",
            "Attribute occurrence counts:\n",
            "  title: 19733\n",
            "  keywords: 19733\n",
            "  abstract: 19733\n",
            "  primary_area: 19733\n",
            "  venue: 19733\n",
            "  venueid: 19733\n",
            "  pdf: 19654\n",
            "  _bibtex: 19733\n",
            "  supplementary_material: 7678\n",
            "  TLDR: 10126\n",
            "  authors: 151\n",
            "  authorids: 151\n",
            "  paperhash: 151\n",
            "  code_of_ethics: 84\n",
            "  submission_guidelines: 84\n",
            "  anonymous_url: 84\n",
            "  no_acknowledgement_section: 84\n",
            "  reciprocal_reviewing_author: 4\n",
            "  reciprocal_reviewing_exemption: 4\n",
            "  resubmission: 4\n",
            "  student_author: 4\n",
            "  large_language_models: 4\n",
            "  reciprocal_reviewing_exemption_reason: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "aiq3AOhfEoeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_data = []\n",
        "for note in notes:\n",
        "    # Extract title value safely\n",
        "    title_val = note.content.get(\"title\", \"\")\n",
        "    if isinstance(title_val, dict) and \"value\" in title_val:\n",
        "        title_val = title_val[\"value\"]\n",
        "    # Skip notes where title starts with 'Null' followed by any non-space chars (one word)\n",
        "    if isinstance(title_val, str) and (re.fullmatch(r\"Null\\S+\", title_val) or len(title_val) < 5):\n",
        "        continue\n",
        "    entry = {}\n",
        "    for key, value in note.content.items():\n",
        "        # Safely extract inner value if present\n",
        "        if isinstance(value, dict) and \"value\" in value:\n",
        "            val = str(value[\"value\"])\n",
        "        else:\n",
        "            val = str(value)\n",
        "        # Special handling for 'pdf' field\n",
        "        if key == \"pdf\":\n",
        "            # Prepend if it's not already a full URL\n",
        "            if val and not val.startswith(\"https://openreview.net/\"):\n",
        "                val = \"https://openreview.net/\" + val.lstrip(\"/\")\n",
        "        entry[key] = val\n",
        "    json_data.append(entry)\n",
        "\n",
        "# Save to JSON file\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") # They update the submission list, so timestamps are added\n",
        "filename = f\"notes_{timestamp}.json\"\n",
        "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(json_data, f, ensure_ascii=False, indent=2)"
      ],
      "metadata": {
        "id": "gQ-GXpwkEpOq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many submissions there are\n",
        "print(f\"Total non-empty submissions: {len(json_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdwdwR4cE3qU",
        "outputId": "9aefd1ab-8695-49d2-80bb-35965a3b9797"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total non-empty submissions: 19731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Database Construction"
      ],
      "metadata": {
        "id": "RwRDsY6FFE6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(filename, \"r\") as f:\n",
        "    note_list = json.load(f)\n",
        "# We use only the first 1000 for demonstration purposes\n",
        "note_list = note_list[:1000]"
      ],
      "metadata": {
        "id": "T0ixmsxVFISg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a persistent chromadb client\n",
        "client = chromadb.PersistentClient(path=\"ICLR2026\")\n",
        "# We use a free local small model, you can use other models or API-gated models\n",
        "embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "    model_name=\"all-MiniLM-L6-v2\"\n",
        ")\n",
        "collection_name = \"MiniLM\"\n",
        "# Just sanity check if there are already existing db for this\n",
        "# If you did not finish last time\n",
        "existing = [c.name for c in client.list_collections()]\n",
        "print(existing)\n",
        "count = 0\n",
        "if collection_name in existing:\n",
        "    collection = client.get_collection(name=collection_name)\n",
        "    count = collection.count()\n",
        "    print(f\"Collection '{collection_name}' already exists with {count} entries.\")\n",
        "\n",
        "    if count > 0:\n",
        "        cont = input(\"Do you want to continue adding to the existing collection? (y/n): \").strip().lower()\n",
        "        if cont != \"y\":\n",
        "            confirm = input(\"Do you want to delete and recreate it instead? (y/n): \").strip().lower()\n",
        "            if confirm == \"y\":\n",
        "                client.delete_collection(name=collection_name)\n",
        "                print(f\"Deleted old collection '{collection_name}'.\")\n",
        "                collection = client.create_collection(name=collection_name, embedding_function=embedding_fn, metadata={\"hnsw:space\": \"cosine\"})\n",
        "                print(f\"Recreated collection '{collection_name}'.\")\n",
        "            else:\n",
        "                print(\"Operation cancelled.\")\n",
        "                exit()\n",
        "        else:\n",
        "            print(\"Continuing to add to existing collection.\")\n",
        "    else:\n",
        "        print(\"Collection exists but has no entries-continuing.\")\n",
        "else:\n",
        "    collection = client.create_collection(name=collection_name, embedding_function=embedding_fn)\n",
        "    print(f\"Created new collection '{collection_name}'.\")\n",
        "\n",
        "# Build a ChromaDB collection that automatically stores embeddings with metadata (e.g., title, keywords) and enables fast retrieval.\n",
        "batch_size = 10  # adjust depending on memory\n",
        "for start in tqdm(range(count, len(note_list), batch_size), desc=\"Inserting papers in batches\"):\n",
        "    batch = note_list[start:start + batch_size]\n",
        "    ids = [str(i) for i in range(start, start + len(batch))]\n",
        "    abstracts = [p.get(\"abstract\", \"\") for p in batch]\n",
        "    metadatas = [{k: v for k, v in p.items() if k != \"abstract\"} for p in batch]\n",
        "\n",
        "    collection.add(\n",
        "        ids=ids,\n",
        "        documents=abstracts, # we use abstracts for embeddings\n",
        "        metadatas=metadatas\n",
        "    )\n",
        "\n",
        "print(f\"Inserted {len(note_list)} papers into ChromaDB in batches of {batch_size}.\")\n",
        "print(f\"Final collection size: {collection.count()} entries.\")"
      ],
      "metadata": {
        "id": "HneRVB_wFrQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "NUj-qvxkHkvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the ChromaDB collection\n",
        "# Not necessary here, but included for reference in a production environment\n",
        "client = chromadb.PersistentClient(path=\"ICLR2026\")\n",
        "embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
        "COLLECTION_NAME = \"MiniLM\"\n",
        "collection = client.get_collection(name=COLLECTION_NAME, embedding_function=embedding_fn)\n",
        "\n",
        "# Query\n",
        "abstract = input(\"Enter your abstract: \")\n",
        "results = collection.query(\n",
        "    query_texts=[abstract],\n",
        "    n_results=3\n",
        ")\n",
        "\n",
        "# See outputs\n",
        "for doc_id, doc, meta, dist in zip(\n",
        "    results[\"ids\"][0],\n",
        "    results[\"documents\"][0],\n",
        "    results[\"metadatas\"][0],\n",
        "    results[\"distances\"][0]\n",
        "):\n",
        "    affinity = (2 - dist) / 2  # affinity score\n",
        "    print(f\"üß© ID: {doc_id}\")\n",
        "    print(f\"üìò Title: {meta.get('title', 'N/A')}\")\n",
        "    print(f\"üè∑Ô∏è Keywords: {meta.get('keywords', 'N/A')}\")\n",
        "    print(f\"üìç Venue: {meta.get('venue', 'N/A')}\")\n",
        "    print(f\"üåê PDF Link: https://openreview.net/{meta.get('pdf', 'N/A')}\")\n",
        "    print(f\"üí´ Affinity Score: {affinity:.4f}\")\n",
        "    print(\"üß† Abstract:\")\n",
        "    print(textwrap.fill(doc.strip(), width=100))  # wrap nicely at 100 chars per line\n",
        "    print(\"-\" * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAS6J4rKHj-n",
        "outputId": "ad382bfc-78c0-4e48-a043-5badf6b64f66"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your abstract: We propose a principled and effective framework for one-step generative modeling. We introduce the notion of average velocity to characterize flow fields, in contrast to instantaneous velocity modeled by Flow Matching methods. A well-defined identity between average and instantaneous velocities is derived and used to guide neural network training. Our method, termed the MeanFlow model, is self-contained and requires no pre-training, distillation, or curriculum learning. MeanFlow demonstrates strong empirical performance: it achieves an FID of 3.43 with a single function evaluation (1-NFE) on ImageNet 256x256 trained from scratch, significantly outperforming previous state-of-the-art one-step diffusion/flow models. Our study substantially narrows the gap between one-step diffusion/flow models and their multi-step predecessors, and we hope it will motivate future research to revisit the foundations of these powerful models.\n",
            "üß© ID: 699\n",
            "üìò Title: Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models\n",
            "üè∑Ô∏è Keywords: ['Energy-Based Model', 'Flow Matching', 'Diffusion', 'Generative Model']\n",
            "üìç Venue: ICLR 2026 Conference Submission\n",
            "üåê PDF Link: https://openreview.net/https://openreview.net/pdf/71503101b00df8b706ad57276d8a980fff35c8d0.pdf\n",
            "üí´ Affinity Score: 0.8582\n",
            "üß† Abstract:\n",
            "We introduce $\\textit{Equilibrium Matching}$ (EqM), a generative modeling framework built from an\n",
            "equilibrium dynamics perspective. EqM discards the non-equilibrium, time-conditional dynamics in\n",
            "traditional diffusion and flow-based generative models and instead learns the equilibrium gradient\n",
            "of an implicit energy landscape. Through this approach, we can adopt an optimization-based sampling\n",
            "process at inference time, where samples are obtained by gradient descent on the learned landscape\n",
            "with adjustable step sizes, adaptive optimizers, and adaptive compute. EqM surpasses the generation\n",
            "performance of diffusion/flow models empirically, achieving a FID of 1.90 on ImageNet\n",
            "256$\\times$256. EqM is also theoretically justified to learn and sample from the data manifold.\n",
            "Beyond generation, EqM is a flexible framework that naturally handles tasks including partially\n",
            "noised image denoising, OOD detection, and image composition. By replacing time-conditional\n",
            "velocities with a unified equilibrium landscape, EqM offers a tighter bridge between flow and\n",
            "energy-based models and a simple route to optimization-driven inference.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "üß© ID: 763\n",
            "üìò Title: SplitMeanFlow: Interval Splitting Consistency in Few-Step Generative Modeling\n",
            "üè∑Ô∏è Keywords: ['text-to-speech', 'flow matching', 'meanflow', 'efficiency', 'speed-quality tradeoff']\n",
            "üìç Venue: ICLR 2026 Conference Submission\n",
            "üåê PDF Link: https://openreview.net/https://openreview.net/pdf/867200760a7832e609a89e7ddf12406b84ba5d47.pdf\n",
            "üí´ Affinity Score: 0.8494\n",
            "üß† Abstract:\n",
            "Flow Matching has achieved prominent performance in generative modeling, yet it is plagued by high\n",
            "computational costs due to iterative sampling. Recent approaches such as MeanFlow address this\n",
            "bottleneck by learning average velocity fields instead of instantaneous velocities. However, we\n",
            "demonstrate that MeanFlow‚Äôs differential formulation is a special case of a more fundamental\n",
            "principle. In this work, we revisit the first principles of average velocity fields and derive a key\n",
            "algebraic identity: Interval Splitting Consistency. Building on this, we propose SplitMeanFlow, a\n",
            "novel framework that directly enforces this algebraic consistency as a core learning objective.\n",
            "Theoretically, we show that SplitMeanFlow recovers MeanFlow‚Äôs differential identity in the limit,\n",
            "thereby establishing a more general and robust basis for average velocity field learning.\n",
            "Practically, SplitMeanFlow simplifies training by eliminating the need for JVP and enables one-step\n",
            "synthesis. Extensive experiments on large-scale speech synthesis tasks verify its superiority:\n",
            "SplitMeanFlow achieves a 10$\\times$ speedup and a 20$\\times$ reduction in computational cost, while\n",
            "preserving speech quality, delivering substantial efficiency gains without compromising generative\n",
            "performance.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "üß© ID: 860\n",
            "üìò Title: Unified Continuous Generative Models for Denoising-based Diffusion\n",
            "üè∑Ô∏è Keywords: ['generative modeling', 'denoising diffusion', 'consistency model', 'image generation']\n",
            "üìç Venue: ICLR 2026 Conference Submission\n",
            "üåê PDF Link: https://openreview.net/https://openreview.net/pdf/be5df6cd8475f363a14a0f34a1f6d89629985e6d.pdf\n",
            "üí´ Affinity Score: 0.8355\n",
            "üß† Abstract:\n",
            "Recent advances in continuous generative models, encompassing multi-step processes such as diffusion\n",
            "and flow matching (typically requiring $8$-$1000$ steps) and few-step methods such as consistency\n",
            "models (typically $1$-$8$ steps), have yielded impressive generative performance.     However,\n",
            "existing work often treats these approaches as distinct paradigms, leading to disparate training and\n",
            "sampling methodologies.     We propose a unified framework for the training, sampling, and analysis\n",
            "of diffusion, flow matching, and consistency models.     Within this framework, we derive a\n",
            "surrogate unified objective that, for the first time, theoretically shows that the few-step\n",
            "objective can be viewed as the multi-step objective plus a regularization term.     Building on this\n",
            "framework, we introduce the **U**nified **C**ontinuous **G**enerative **M**odels **T**rainer and\n",
            "**S**ampler (**UCGM**), which enables efficient and stable training of both multi-step and few-step\n",
            "models.     Empirically, our framework achieves state-of-the-art results.     On ImageNet\n",
            "$256\\times256$ with a $675\\text{M}$ diffusion transformer, UCGM-T trains a multi-step model\n",
            "achieving $1.30$ FID in $20$ steps, and a few-step model achieving $1.42$ FID in only $2$ steps.\n",
            "Moreover, applying UCGM-S to REPA-E improves its FID from $1.26$ (at $250$ steps) to $1.06$ in only\n",
            "$40$ steps, without additional cost.\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contact"
      ],
      "metadata": {
        "id": "Pndh9NU1KsAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "My collaborator [Jingxiang Qu](https://qujx.github.io/), my undergraduate mentee [Yichi Zhang](https://yichixiaoju.github.io/YichiZhang.github.io/), and I (and GPT) are actively expanding this system to include more venues, employ advanced similarity-matching algorithms, train specialized models, support multi-agent collaboration, handle batch inputs/outputs, and provide an improved user interface. We welcome feedback and collaborations, feel free to [contact me](https://wenhangao21.github.io/)."
      ],
      "metadata": {
        "id": "-zYBFxh0KuOC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}