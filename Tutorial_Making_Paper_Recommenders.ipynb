{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TL;DR:** A tutorial on creating a simple paper recommender system using embeddings from paper abstracts.\n",
        "\n",
        "Recently, I shared a tool that helps people find relevant papers among 17,000+ ICLR 2026 submissions. To my surprise, the post attracted quite a bit of attention, much more than any of my posts about [my research](https://wenhangao21.github.io/tech_blogs/)😢.\n",
        "\n",
        "- [ICLR2026 Paper Finder on Hugging Face](https://huggingface.co/spaces/wenhanacademia/ICLR2026_PaperFinder)\n",
        "- [Open Source Repository](https://github.com/wenhangao21/ICLR26_Paper_Finder?tab=readme-ov-file)\n",
        "\n",
        "A few people reached out asking how the app was built. It’s actually very simple, so I thought I’d write a short blog/tutorial about it. **The algorithm took me less than 30 minutes to write (with the help from GPT-5-Instant)**, though the user interface ended up taking an entire afternoon (with the help from GPT-5-Instant). **You can run this notebook for free on Google Colab if you don’t have Jupyter Notebook installed.**"
      ],
      "metadata": {
        "id": "o6JH2VtvijAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Simple Paper Recommender with Language Embedding Models"
      ],
      "metadata": {
        "id": "WMD2PEkokpun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overall Pipeline"
      ],
      "metadata": {
        "id": "xwK_RAe02aeg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Data Retrieval:** Collect all paper submissions from OpenReview (For other venues, you can find API for or write a web scraper).\n",
        "2. **Data Processing:** Clean and structure the retrieved data into a usable format for downstream tasks.\n",
        "3. **Vector Database Construction:** Generate abstract embeddings with language embedding models and store them in a vector database to enable fast semantic similarity search (approximate k-NN).\n",
        "4. **Inference:** Query the database to identify the top-K most relevant submissions based on semantic similarity.\n",
        "\n",
        "Note:\n",
        "- **Data Retrieval and Processing:** We are given a collection of text documents (a collection of abstracts in our case):\n",
        "$$\n",
        "\\mathcal{T}=\\left\\{t_1, t_2, \\ldots, t_N\\right\\}.\\\\\n",
        "$$\n",
        "\n",
        "- **Vector Database Construction:** An embedding model maps a given text $t$ (an abstract in our case) into a high-dimensional continuous vector:\n",
        "  $$\n",
        "  \\operatorname{Embedding}_\\theta: t_i \\rightarrow e_i \\in \\mathbb{R}^d,\n",
        "  $$\n",
        "  where $\\operatorname{Embedding}_\\theta$ is the embedding model (you can think of the text embedding being the last feature before the the LM Head in a modern LLM), and $d$ is a fixed embedding dimension.\n",
        "\n",
        "  Now, we have a collection of embeddings $\\mathcal{E}=\\left\\{e_1, e_2, \\ldots, e_N\\right\\}$, and you can run approximate KNN algorithms (e.g. [FAISS](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)) on it for semantic search.\n"
      ],
      "metadata": {
        "id": "vOJE8wUn2cgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and Import Dependencies"
      ],
      "metadata": {
        "id": "VaphEiOZktDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install chromadb markdown google-generativeai sentence_transformers openreview-py"
      ],
      "metadata": {
        "collapsed": true,
        "id": "b3lSHp28lfKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openreview\n",
        "from openreview import tools\n",
        "import json\n",
        "import re\n",
        "import chromadb\n",
        "import google.generativeai as genai\n",
        "import chromadb.utils.embedding_functions as embedding_functions\n",
        "import textwrap\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "DA4ket59lL-8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Retrieval"
      ],
      "metadata": {
        "id": "_SfaAZvFk-8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the OpenReview API client\n",
        "client = openreview.api.OpenReviewClient(\n",
        "    baseurl=\"https://api2.openreview.net\",\n",
        "    username=\"<your openreview email>\",  # enter your openreview email and password here\n",
        "    password=\"<your openreview password>\"\n",
        ")\n",
        "# Extract all submissions to ICLR 2026\n",
        "notes = list(tools.iterget_notes(\n",
        "    client,\n",
        "    invitation=\"ICLR.cc/2026/Conference/-/Submission\"\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGZgZ0wxB5-9",
        "outputId": "15646f11-23ad-458b-8080-96050e9f14c9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1944091578.py:8: DeprecationWarning: Call to deprecated function (or staticmethod) iterget_notes. (Use client.get_all_notes() instead) -- Deprecated since version 1.52.6.\n",
            "  notes = list(tools.iterget_notes(\n",
            "Getting Notes: 100%|█████████▉| 19714/19734 [00:11<00:00, 1789.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many submissions there are\n",
        "print(f\"Total submissions: {len(notes)}\")\n",
        "# Get all the possible atrributes\n",
        "key_counter = Counter(k for note in notes for k in note.content.keys())\n",
        "print(\"\\nAttribute occurrence counts:\")\n",
        "for key, count in key_counter.items():\n",
        "    print(f\"  {key}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss2AkqXMEBFu",
        "outputId": "26ef7231-8028-4489-ca91-dd42506cb614"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total submissions: 19734\n",
            "\n",
            "Attribute occurrence counts:\n",
            "  title: 19734\n",
            "  keywords: 19734\n",
            "  abstract: 19734\n",
            "  primary_area: 19734\n",
            "  venue: 19734\n",
            "  venueid: 19734\n",
            "  pdf: 19655\n",
            "  _bibtex: 19734\n",
            "  supplementary_material: 7678\n",
            "  TLDR: 10126\n",
            "  authors: 141\n",
            "  authorids: 141\n",
            "  paperhash: 141\n",
            "  code_of_ethics: 83\n",
            "  submission_guidelines: 83\n",
            "  anonymous_url: 83\n",
            "  no_acknowledgement_section: 83\n",
            "  reciprocal_reviewing_author: 3\n",
            "  reciprocal_reviewing_exemption: 3\n",
            "  resubmission: 3\n",
            "  student_author: 3\n",
            "  large_language_models: 3\n",
            "  reciprocal_reviewing_exemption_reason: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "aiq3AOhfEoeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_data = []\n",
        "for note in notes:\n",
        "    # Extract title value safely\n",
        "    title_val = note.content.get(\"title\", \"\")\n",
        "    if isinstance(title_val, dict) and \"value\" in title_val:\n",
        "        title_val = title_val[\"value\"]\n",
        "    # Skip notes where title starts with 'Null' followed by any non-space chars (one word)\n",
        "    if isinstance(title_val, str) and re.fullmatch(r\"Null\\S+\", title_val):\n",
        "        continue\n",
        "    entry = {}\n",
        "    for key, value in note.content.items():\n",
        "        # Safely extract inner value if present\n",
        "        if isinstance(value, dict) and \"value\" in value:\n",
        "            val = str(value[\"value\"])\n",
        "        else:\n",
        "            val = str(value)\n",
        "        # Special handling for 'pdf' field\n",
        "        if key == \"pdf\":\n",
        "            # Prepend if it's not already a full URL\n",
        "            if val and not val.startswith(\"https://openreview.net/\"):\n",
        "                val = \"https://openreview.net/\" + val.lstrip(\"/\")\n",
        "        entry[key] = val\n",
        "    json_data.append(entry)\n",
        "\n",
        "# Save to JSON file\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") # They update the submission list, so timestamps are added\n",
        "filename = f\"notes_{timestamp}.json\"\n",
        "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(json_data, f, ensure_ascii=False, indent=2)"
      ],
      "metadata": {
        "id": "gQ-GXpwkEpOq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many submissions there are\n",
        "print(f\"Total non-empty submissions: {len(json_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdwdwR4cE3qU",
        "outputId": "fda8c8c4-ea37-45af-ceeb-a599bfd09a22"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total non-empty submissions: 19733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Database Construction"
      ],
      "metadata": {
        "id": "RwRDsY6FFE6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(filename, \"r\") as f:\n",
        "    note_list = json.load(f)\n",
        "# We use only the first 1000 for demonstration purposes\n",
        "note_list = note_list[:1000]"
      ],
      "metadata": {
        "id": "T0ixmsxVFISg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a persistent chromadb client\n",
        "client = chromadb.PersistentClient(path=\"ICLR2026\")\n",
        "# We use a free local small model, you can use other models or API-gated models\n",
        "embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "    model_name=\"all-MiniLM-L6-v2\"\n",
        ")\n",
        "collection_name = \"MiniLM\"\n",
        "# Just sanity check if there are already existing db for this\n",
        "# If you did not finish last time\n",
        "existing = [c.name for c in client.list_collections()]\n",
        "print(existing)\n",
        "count = 0\n",
        "if collection_name in existing:\n",
        "    collection = client.get_collection(name=collection_name)\n",
        "    count = collection.count()\n",
        "    print(f\"Collection '{collection_name}' already exists with {count} entries.\")\n",
        "\n",
        "    if count > 0:\n",
        "        cont = input(\"Do you want to continue adding to the existing collection? (y/n): \").strip().lower()\n",
        "        if cont != \"y\":\n",
        "            confirm = input(\"Do you want to delete and recreate it instead? (y/n): \").strip().lower()\n",
        "            if confirm == \"y\":\n",
        "                client.delete_collection(name=collection_name)\n",
        "                print(f\"Deleted old collection '{collection_name}'.\")\n",
        "                collection = client.create_collection(name=collection_name, embedding_function=embedding_fn)\n",
        "                print(f\"Recreated collection '{collection_name}'.\")\n",
        "            else:\n",
        "                print(\"Operation cancelled.\")\n",
        "                exit()\n",
        "        else:\n",
        "            print(\"Continuing to add to existing collection.\")\n",
        "    else:\n",
        "        print(\"Collection exists but has no entries-continuing.\")\n",
        "else:\n",
        "    collection = client.create_collection(name=collection_name, embedding_function=embedding_fn)\n",
        "    print(f\"Created new collection '{collection_name}'.\")\n",
        "\n",
        "# Build a ChromaDB collection that automatically stores embeddings with metadata (e.g., title, keywords) and enables fast retrieval.\n",
        "batch_size = 10  # adjust depending on memory\n",
        "for start in tqdm(range(count, len(note_list), batch_size), desc=\"Inserting papers in batches\"):\n",
        "    batch = note_list[start:start + batch_size]\n",
        "    ids = [str(i) for i in range(start, start + len(batch))]\n",
        "    abstracts = [p.get(\"abstract\", \"\") for p in batch]\n",
        "    metadatas = [{k: v for k, v in p.items() if k != \"abstract\"} for p in batch]\n",
        "\n",
        "    collection.add(\n",
        "        ids=ids,\n",
        "        documents=abstracts, # we use abstracts for embeddings\n",
        "        metadatas=metadatas\n",
        "    )\n",
        "\n",
        "print(f\"Inserted {len(note_list)} papers into ChromaDB in batches of {batch_size}.\")\n",
        "print(f\"Final collection size: {collection.count()} entries.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HneRVB_wFrQi",
        "outputId": "bb28de38-a688-47a9-826e-df78839c7a34"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MiniLM']\n",
            "Collection 'MiniLM' already exists with 210 entries.\n",
            "Do you want to continue adding to the existing collection? (y/n): y\n",
            "Continuing to add to existing collection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inserting papers in batches: 100%|██████████| 79/79 [01:47<00:00,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 1000 papers into ChromaDB in batches of 10.\n",
            "Final collection size: 1000 entries.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "NUj-qvxkHkvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the ChromaDB collection\n",
        "# Not necessary here, but included for reference in a production environment\n",
        "client = chromadb.PersistentClient(path=\"ICLR2026\")\n",
        "embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
        "COLLECTION_NAME = \"MiniLM\"\n",
        "collection = client.get_collection(name=COLLECTION_NAME, embedding_function=embedding_fn)\n",
        "\n",
        "# Query\n",
        "abstract = input(\"Enter your abstract: \")\n",
        "results = collection.query(\n",
        "    query_texts=[abstract],\n",
        "    n_results=3\n",
        ")\n",
        "\n",
        "# See outputs\n",
        "for doc_id, doc, meta in zip(results[\"ids\"][0], results[\"documents\"][0], results[\"metadatas\"][0]):\n",
        "    print(f\"🧩 ID: {doc_id}\")\n",
        "    print(f\"📘 Title: {meta.get('title', 'N/A')}\")\n",
        "    print(f\"🏷️ Keywords: {meta.get('keywords', 'N/A')}\")\n",
        "    print(f\"📍 Venue: {meta.get('venue', 'N/A')}\")\n",
        "    print(f\"🌐 PDF Link: https://openreview.net/{meta.get('pdf', 'N/A')}\")\n",
        "    print(\"🧠 Abstract:\")\n",
        "    print(textwrap.fill(doc.strip(), width=100))  # wrap nicely at 100 chars per line\n",
        "\n",
        "    print(\"-\" * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAS6J4rKHj-n",
        "outputId": "ffc750ac-6042-47ae-888e-ae8ee30718a6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your abstract: In recent years, neural operators have emerged as a prominent approach for learning mappings between function spaces, such as the solution operators of parametric PDEs. A notable example is the Fourier Neural Operator (FNO), which models the integral kernel as a convolution operator and uses the Convolution Theorem to learn the kernel directly in the frequency domain. The parameters are decoupled from the resolution of the data, allowing the FNO to take inputs of different resolutions. However, training at a lower resolution and inferring at a finer resolution does not guarantee consistent performance, nor can fine details, present only in fine-scale data, be learned solely from coarse data. In this work, we address this misconception by defining and examining the discretization mismatch error: the discrepancy between the outputs of the neural operator when using different discretizations of the input data. We demonstrate that neural operators may suffer from discretization mismatch errors that hinder their effectiveness when inferred on data with resolutions different from that of the training data or when trained on data with varying resolutions. As neural operators underpin many critical cross-resolution scientific tasks, such as climate modeling and fluid dynamics, understanding discretization mismatch errors is essential. Based on our findings, we propose a Cross-Resolution Operator-learning Pipeline that is free of aliasing and discretization mismatch errors, enabling efficient cross-resolution and multi-spatial-scale learning, and resulting in superior performance.\n",
            "🧩 ID: 922\n",
            "📘 Title: Multi-Operator Few-Shot Learning for Generalization Across PDE Families\n",
            "🏷️ Keywords: ['PDEs', 'Neural Operator', 'AI for science', 'Scientific Machine Learning', 'Operator Learning', 'Multimodal Machine Learning', 'Domain Adaptation']\n",
            "📍 Venue: ICLR 2026 Conference Submission\n",
            "🌐 PDF Link: https://openreview.net/https://openreview.net/pdf/c061ec2e5d8cff0c7f3e4cb0727f912d61b5353b.pdf\n",
            "🧠 Abstract:\n",
            "Learning solution operators for partial differential equations (PDEs) has become a foundational task\n",
            "in scientific machine learning. However, existing neural operator methods require abundant training\n",
            "data for each specific PDE and lack the ability to generalize across PDE families. In this work, we\n",
            "propose MOFS: a unified multimodal framework for multi-operator few-shot learning, which aims to\n",
            "generalize to unseen PDE operators using only a few demonstration examples. Our method integrates\n",
            "three key components: (i) multi-task self-supervised pretraining of a shared Fourier Neural Operator\n",
            "(FNO) encoder to reconstruct masked spatial fields and predict frequency spectra, (ii) text-\n",
            "conditioned operator embeddings derived from statistical summaries of input-output fields, and (iii)\n",
            "memory-augmented multimodal prompting with gated fusion and cross-modal gradient-based attention. We\n",
            "adopt a two-stage training paradigm that first learns prompt-conditioned inference on seen operators\n",
            "and then applies end-to-end contrastive fine-tuning to align latent representations across vision,\n",
            "frequency, and text modalities. Experiments on PDE benchmarks, including Darcy Flow and\n",
            "Incompressible Navier Stokes variants, demonstrate that our model outperforms existing operator\n",
            "learning baselines in few-shot generalization. Extensive ablations validate the contributions of\n",
            "each modality and training component. Our approach offers a new foundation for universal and data-\n",
            "efficient operator learning across scientific domains.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "🧩 ID: 837\n",
            "📘 Title: Deep Gaussian Processes for Functional Maps\n",
            "🏷️ Keywords: ['Functional mapping', 'Gaussian Process']\n",
            "📍 Venue: ICLR 2026 Conference Submission\n",
            "🌐 PDF Link: https://openreview.net/https://openreview.net/pdf/fc69a31286fb3523f429656c3a0124b1712a7520.pdf\n",
            "🧠 Abstract:\n",
            "Learning mappings between functional spaces, also known as function-on-function regression, plays a\n",
            "crucial role in functional data analysis and has broad applications, DGP-FM spatiotemporal\n",
            "forecasting, curve prediction, and climate modeling. Existing approaches, such as functional linear\n",
            "models and neural operators, either fail to capture complex nonlinearities or lack capacity to\n",
            "provide reliable uncertainty quantification under noisy, sparse, and irregular sampled data. To\n",
            "address these issues, we propose Deep Gaussian Processes for Functional Maps (DGP-FM). Our method\n",
            "designs a sequence of GP-based linear and nonlinear transformations, leveraging integral transforms\n",
            "of kernels, GP interpolation, and nonlinear activations sampled from GPs. A key insight simplifies\n",
            "implementation: under fixed sampling locations, discrete approximations of kernel integral\n",
            "transforms collapse into direct functional integral transforms, enabling flexible incorporation of\n",
            "various integral transform designs. To achieve scalable probabilistic inference, we use inducing\n",
            "points and whitening transformations to develop a variational learning algorithm. Empirical results\n",
            "on real-world and PDE benchmark datasets demonstrate that the advantage of DGP-FM in both predictive\n",
            "performance and uncertainty calibration.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "🧩 ID: 55\n",
            "📘 Title: Towards Generalizable PDE Dynamics Forecasting via Physics-Guided Invariant Learning\n",
            "🏷️ Keywords: ['PDE Dynamics Forecasting', 'OOD Generalization', 'Invariant Learning']\n",
            "📍 Venue: ICLR 2026 Conference Submission\n",
            "🌐 PDF Link: https://openreview.net/https://openreview.net/pdf/d9ab52ff24bd9278a2abe4753f4e24abcc8861a2.pdf\n",
            "🧠 Abstract:\n",
            "Advanced deep learning-based approaches have been actively applied to forecast the spatiotemporal\n",
            "physical dynamics governed by partial differential equations (PDEs), which acts as a critical\n",
            "procedure in tackling many science and engineering problems. As real-world physical environments\n",
            "like PDE system parameters are always capricious, how to generalize across unseen out-of-\n",
            "distribution (OOD) forecasting scenarios using limited training data is of great importance. To\n",
            "bridge this barrier, existing methods focus on discovering domain-generalizable representations\n",
            "across various PDE dynamics trajectories. However, their zero-shot OOD generalization capability\n",
            "remains deficient, since extra test-time samples for domain-specific adaptation are still required.\n",
            "This is because the fundamental physical invariance in PDE dynamical systems are yet to be\n",
            "investigated or integrated. To this end, we first explicitly define a two-fold PDE invariance\n",
            "principle, which points out that ingredient operators and their composition relationships remain\n",
            "invariant across different domains and PDE system evolution. Next, to capture this two-fold PDE\n",
            "invariance, we propose a physics-guided invariant learning method termed iMOOE, featuring an\n",
            "Invariance-aligned Mixture Of Operator Expert architecture and a frequency-enriched invariant\n",
            "learning objective. Extensive experiments across simulated benchmarks and real-world applications\n",
            "validate iMOOE's superior in-distribution performance and zero-shot generalization capabilities on\n",
            "diverse OOD forecasting scenarios.\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contact"
      ],
      "metadata": {
        "id": "Pndh9NU1KsAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "My collaborator [Jingxiang Qu](https://qujx.github.io/), my undergraduate mentee [Yichi Zhang](https://yichixiaoju.github.io/YichiZhang.github.io/), and I (and GPT) are actively expanding this system to include more venues, employ advanced similarity-matching algorithms, train specialized models, support multi-agent collaboration, handle batch inputs/outputs, and provide an improved user interface. We welcome feedback and collaborations, feel free to [contact me](https://wenhangao21.github.io/)."
      ],
      "metadata": {
        "id": "-zYBFxh0KuOC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xwK_RAe02aeg",
        "VaphEiOZktDL",
        "aiq3AOhfEoeb",
        "RwRDsY6FFE6k"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}